\documentclass{article}
 \usepackage[BoldFont,SlantFont,CJKchecksingle]{xeCJK}
\setCJKmainfont[BoldFont=Evermore Hei]{Evermore Kai}

\usepackage{amsmath}


\begin{document}

\title{误差反传算法}
\author{邢超(xingnix@live.com)}
\maketitle


\section{ $\Delta E,\Delta O,\Delta W$}
% 利用梯度推导反传公式的过程中可以采用小扰动方法简化推导步骤

对于第i层网络：
\begin{align*}
\vec O_i &=F_i(W_i\vec X_i+\vec b_i)\\
&=\begin{bmatrix}
f_i(\vec w_1 \vec X_i+b_{i,1})  &  f_i(\vec w_2 \vec X_i+b_{i,2}) & \cdots & f_i(\vec w_n \vec X_i +b_{i,n})
\end{bmatrix}^T
\end{align*}
其中：
\begin{itemize}
\item $\vec O_i$ 为第i层网络输出 ，
\item $\vec X_i$ 为第i层网络输入，等于第 $i-1$ 层网络输出 $\vec O_{i-1}$
\item $\vec w_j$ 为第i层网络权值矩阵 $W_i$ 的第j行， 
\item $b_{i,j}$ 为向量 $\vec b_i$ 的第j个元素。
\end{itemize}

对于 $W_i$ 的一个微小变化 $\Delta W_i$ ，得：
\begin{align*}
\Delta \vec O_i &=\begin{bmatrix}
f'_i(\vec w_1 \vec X_i+b_{i,1})\Delta \vec w_1 \vec X_i  &  f'_i(\vec w_2 \vec X_i+b_{i,2})\Delta \vec w_2 \vec X_i & \cdots & f'_i(\vec w_n \vec X_i +b_{i,n})\Delta \vec w_n \vec X_i
\end{bmatrix}^T \\
&=diag[F'_i(W_i\vec X_i+\vec b_i)]\Delta W\vec X_i \\
&=diag(F'_i)\Delta W_i \vec X_i
\end{align*}


其中 $diag(F)$ 表示主对角元素为向量 F的元素的方阵。



对于N层网络的误差函数：

\[E=(\vec{Y}-\vec O_N)^T(\vec{Y}-\vec O_N)\]


误差函数的增量：
\begin{align*}
\Delta E &=-2(\vec Y-\vec O_N)^T\cdot \Delta\vec O_N\\
&=-2(\vec Y-\vec O_N)^T\cdot diag(F'_N)\Delta W_N \vec X_N\\
\frac{\partial E}{\partial W_N}&=-2 diag(F'_N)\cdot(\vec Y-\vec O_N)\cdot \vec X_N^T
\end{align*}

\section{反向传播}
根据链式法则：
\begin{align*}
\Delta \vec O_i&=\begin{bmatrix}
f'_i(\vec w_1 \vec X_i+b_{i,1}) \vec w_1 \Delta\vec X_i  &  f'_i(\vec w_2 \vec X_i+b_{i,2}) \vec w_2 \Delta\vec X_i & \cdots & f'_i(\vec w_n \vec X_i +b_{i,n}) \vec w_n \Delta\vec X_i
\end{bmatrix}^T \\
&=diag(F'_i)W_i \Delta\vec X_i\\
\Delta E &= 2(\vec O_N-\vec Y)^T\cdot diag(F'_N) \cdot W_N \cdot \Delta \vec X_N\\
&= 2(\vec O_N-\vec Y)^T\cdot diag(F'_N) \cdot W_N \cdot \Delta \vec O_{N-1}\\
&=2(\vec O_N-\vec Y)^T\cdot diag(F'_N) \cdot W_N \cdot diag(F'_{N-1})\cdot \Delta W_N \cdot \vec X_{N-1}
\end{align*}

对于N层网络可得：
\begin{align*}
\Delta E &= \vec{\alpha}^T\cdot\Delta W_i\cdot \vec{\beta} \\
\frac{\partial E}{\partial W_i} &= \vec{\alpha}\cdot\vec \beta^T
\end{align*}
其中：
\begin{align*}
\vec{\alpha}^T&=2(\vec O_N-\vec Y)^T\cdot diag(F'_N) \cdot \left[\prod_{n=i+1}^{N} W_n \cdot diag(F'_{n-1})\right] \\
\vec{\beta}&=\vec{X_i}\qquad (\text{ inputs of the i'th layer})
\end{align*}
反向传播：
\begin{align*}
\vec\delta_N&=[2(\vec Y_o-\vec Y_E)^T\cdot diag(F'_N)]^T \\
            &= diag(F'_N)\cdot 2(\vec Y_o-\vec Y_E) \\
\vec\delta_n&=  diag(F'_n)\cdot W_{n+1}^T \cdot\vec\delta_{n+1} \\
\Delta W_i &=\delta_i \cdot \vec X_i^T
\end{align*}


\section{偏置向量}
对偏置向量的更新可考虑增广权植矩阵 $[W|b]$ ,增广输入 $\begin{bmatrix} \vec X_o  \\ 1\end{bmatrix}$ 。令 $\beta=\begin{bmatrix} \vec X_o \\ 1\end{bmatrix}$ 即可得到增广权值矩阵的更新公式。













\end{document}
